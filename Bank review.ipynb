{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer                                                         # for lemmatization\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('BankReviews.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>BankName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>5</td>\n",
       "      <td>I had the pleasure of working with Wyndham Cap...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>5</td>\n",
       "      <td>My experience with Mattison was beyond greatly...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>5</td>\n",
       "      <td>Patrick answered all my questions by email imm...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-09-04</td>\n",
       "      <td>5</td>\n",
       "      <td>I loved working with this group of people! The...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>5</td>\n",
       "      <td>Great web interface for both the loan applicat...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>5</td>\n",
       "      <td>Working with Michelle and Wyndham went really ...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-02-06</td>\n",
       "      <td>5</td>\n",
       "      <td>usten Butler brought the humanity and connecti...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-06-11</td>\n",
       "      <td>5</td>\n",
       "      <td>Jay was easy to get a hold of if I had any que...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-03-04</td>\n",
       "      <td>5</td>\n",
       "      <td>If I had a million Friends I would recommend a...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>5</td>\n",
       "      <td>Chaz was fantastic throughout the entire lendi...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>5</td>\n",
       "      <td>Austen has been awsome in every step of the wa...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>5</td>\n",
       "      <td>The salesperson kept pushing a cash out refi o...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-02-24</td>\n",
       "      <td>1</td>\n",
       "      <td>This was the worst experience ever. It was lik...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-03-14</td>\n",
       "      <td>1</td>\n",
       "      <td>A good rate but a very frustrating process, co...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>They were not upfront. Learn from my mistake.....</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016-06-26</td>\n",
       "      <td>1</td>\n",
       "      <td>Initially, the Mortgage Broker was very friend...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016-06-26</td>\n",
       "      <td>1</td>\n",
       "      <td>Initially, the Mortgage Broker was very friend...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>5</td>\n",
       "      <td>I worked with Kory and Carla at NASB. They wer...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-10-11</td>\n",
       "      <td>5</td>\n",
       "      <td>Kory was by far the best loan officer I have e...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>5</td>\n",
       "      <td>Expert loan officer, well versed in VA and the...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>5</td>\n",
       "      <td>The NASB team went above and beyond for me and...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>5</td>\n",
       "      <td>Dallas Goodlet and his entire team are deservi...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>5</td>\n",
       "      <td>Comments: To begin my wife and I were at the p...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>5</td>\n",
       "      <td>Working with Jon was such an amazing experienc...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>5</td>\n",
       "      <td>NASB was amazing to work with! The pre-approva...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nJoey was knowledgeable, very accessible an...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nI was hesitant to use a non-local mortgage...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nI was hesitant to use a non-local mortgage...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nSteve got it done when others couldn't. 30...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nVery professional and customer oriented.\\r...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nSteve was very responsive and patient with...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nGreat bank with great products.  Easily th...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nDallas is very experienced and knowledgeab...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nI was extremely impressed with the proffes...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nI was extremely impressed with the proffes...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nRC Malcolm was excellent, he stayed on top...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nExcellent service . RC stayed on top of ev...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nThey completed everything on time to get u...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nBrad was helpful through the entire proces...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>2017-12-02</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nI will recommend everyone I know to NASB a...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>5</td>\n",
       "      <td>\\r\\nOur refinance process was a dream once we ...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nThe closing process for a VA loan went smo...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2017-03-19</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nMiserable experience. They screwed up ever...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2016-11-20</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nOur loan officer was happy to communicate ...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>2016-06-11</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nOur loan officer was happy to communicate ...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nStarted refinance with Nick things were go...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\ncan someone explain why the APR is more th...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nThis loan started off quite well. Our rep,...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nBuilt new home and wanted to get a small m...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nThis Lender contacted my previous phone nu...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2016-02-06</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nI never write reviews but had to this time...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2016-07-25</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nIt all started when Bob G ran a credit che...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2017-09-27</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nWhat a horrible experience. We have excell...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2017-12-24</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nRep was extremely professional, friendly, ...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2017-03-19</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nI was working with a loan consultant from ...</td>\n",
       "      <td>North American Savings Bank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Stars                                            Reviews  \\\n",
       "0   2017-04-10      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1   2017-02-10      5  Matthew Richardson is professional and helpful...   \n",
       "2   2017-08-21      5  We had a past experience with Wyndham Mortgage...   \n",
       "3   2017-12-17      5  We have been dealing with Brad Thomka from the...   \n",
       "4   2016-05-27      5  I can't express how grateful I am for the supp...   \n",
       "5   2016-12-20      5  I had the pleasure of working with Wyndham Cap...   \n",
       "6   2017-12-17      5  My experience with Mattison was beyond greatly...   \n",
       "7   2016-08-16      5  Patrick answered all my questions by email imm...   \n",
       "8   2017-09-04      5  I loved working with this group of people! The...   \n",
       "9   2016-03-22      5  Great web interface for both the loan applicat...   \n",
       "10  2017-04-02      5  Working with Michelle and Wyndham went really ...   \n",
       "11  2016-02-06      5  usten Butler brought the humanity and connecti...   \n",
       "12  2016-06-11      5  Jay was easy to get a hold of if I had any que...   \n",
       "13  2017-03-04      5  If I had a million Friends I would recommend a...   \n",
       "14  2016-11-06      5  Chaz was fantastic throughout the entire lendi...   \n",
       "15  2016-07-03      5  Austen has been awsome in every step of the wa...   \n",
       "16  2016-10-07      5  The salesperson kept pushing a cash out refi o...   \n",
       "17  2017-02-24      1  This was the worst experience ever. It was lik...   \n",
       "18  2016-03-14      1  A good rate but a very frustrating process, co...   \n",
       "19  2017-08-13      1  They were not upfront. Learn from my mistake.....   \n",
       "20  2016-06-26      1  Initially, the Mortgage Broker was very friend...   \n",
       "21  2016-06-26      1  Initially, the Mortgage Broker was very friend...   \n",
       "22  2016-01-15      5  I worked with Kory and Carla at NASB. They wer...   \n",
       "23  2017-10-11      5  Kory was by far the best loan officer I have e...   \n",
       "24  2016-10-14      5  Expert loan officer, well versed in VA and the...   \n",
       "25  2016-01-08      5  The NASB team went above and beyond for me and...   \n",
       "26  2016-10-22      5  Dallas Goodlet and his entire team are deservi...   \n",
       "27  2017-09-12      5  Comments: To begin my wife and I were at the p...   \n",
       "28  2017-05-24      5  Working with Jon was such an amazing experienc...   \n",
       "29  2017-05-02      5  NASB was amazing to work with! The pre-approva...   \n",
       "..         ...    ...                                                ...   \n",
       "475 2017-08-06      5  \\r\\nJoey was knowledgeable, very accessible an...   \n",
       "476 2016-10-29      5  \\r\\nI was hesitant to use a non-local mortgage...   \n",
       "477 2016-12-05      5  \\r\\nI was hesitant to use a non-local mortgage...   \n",
       "478 2017-10-04      5  \\r\\nSteve got it done when others couldn't. 30...   \n",
       "479 2016-08-31      5  \\r\\nVery professional and customer oriented.\\r...   \n",
       "480 2017-05-09      5  \\r\\nSteve was very responsive and patient with...   \n",
       "481 2016-10-22      5  \\r\\nGreat bank with great products.  Easily th...   \n",
       "482 2017-09-12      5  \\r\\nDallas is very experienced and knowledgeab...   \n",
       "483 2016-01-23      5  \\r\\nI was extremely impressed with the proffes...   \n",
       "484 2017-09-12      5  \\r\\nI was extremely impressed with the proffes...   \n",
       "485 2017-05-24      5  \\r\\nRC Malcolm was excellent, he stayed on top...   \n",
       "486 2016-10-22      5  \\r\\nExcellent service . RC stayed on top of ev...   \n",
       "487 2017-08-06      5  \\r\\nThey completed everything on time to get u...   \n",
       "488 2017-05-09      5  \\r\\nBrad was helpful through the entire proces...   \n",
       "489 2017-12-02      5  \\r\\nI will recommend everyone I know to NASB a...   \n",
       "490 2016-05-12      5  \\r\\nOur refinance process was a dream once we ...   \n",
       "491 2017-01-26      1  \\r\\nThe closing process for a VA loan went smo...   \n",
       "492 2017-03-19      1  \\r\\nMiserable experience. They screwed up ever...   \n",
       "493 2016-11-20      1  \\r\\nOur loan officer was happy to communicate ...   \n",
       "494 2016-06-11      1  \\r\\nOur loan officer was happy to communicate ...   \n",
       "495 2016-01-23      1  \\r\\nStarted refinance with Nick things were go...   \n",
       "496 2017-01-11      1  \\r\\ncan someone explain why the APR is more th...   \n",
       "497 2016-11-06      1  \\r\\nThis loan started off quite well. Our rep,...   \n",
       "498 2016-05-27      1  \\r\\nBuilt new home and wanted to get a small m...   \n",
       "499 2016-03-22      1  \\r\\nThis Lender contacted my previous phone nu...   \n",
       "500 2016-02-06      1  \\r\\nI never write reviews but had to this time...   \n",
       "501 2016-07-25      1  \\r\\nIt all started when Bob G ran a credit che...   \n",
       "502 2017-09-27      1  \\r\\nWhat a horrible experience. We have excell...   \n",
       "503 2017-12-24      1  \\r\\nRep was extremely professional, friendly, ...   \n",
       "504 2017-03-19      1  \\r\\nI was working with a loan consultant from ...   \n",
       "\n",
       "                        BankName  \n",
       "0       Wyndham Capital Mortgage  \n",
       "1       Wyndham Capital Mortgage  \n",
       "2       Wyndham Capital Mortgage  \n",
       "3       Wyndham Capital Mortgage  \n",
       "4       Wyndham Capital Mortgage  \n",
       "5       Wyndham Capital Mortgage  \n",
       "6       Wyndham Capital Mortgage  \n",
       "7       Wyndham Capital Mortgage  \n",
       "8       Wyndham Capital Mortgage  \n",
       "9       Wyndham Capital Mortgage  \n",
       "10      Wyndham Capital Mortgage  \n",
       "11      Wyndham Capital Mortgage  \n",
       "12      Wyndham Capital Mortgage  \n",
       "13      Wyndham Capital Mortgage  \n",
       "14      Wyndham Capital Mortgage  \n",
       "15      Wyndham Capital Mortgage  \n",
       "16      Wyndham Capital Mortgage  \n",
       "17      Wyndham Capital Mortgage  \n",
       "18      Wyndham Capital Mortgage  \n",
       "19      Wyndham Capital Mortgage  \n",
       "20      Wyndham Capital Mortgage  \n",
       "21      Wyndham Capital Mortgage  \n",
       "22   North American Savings Bank  \n",
       "23   North American Savings Bank  \n",
       "24   North American Savings Bank  \n",
       "25   North American Savings Bank  \n",
       "26   North American Savings Bank  \n",
       "27   North American Savings Bank  \n",
       "28   North American Savings Bank  \n",
       "29   North American Savings Bank  \n",
       "..                           ...  \n",
       "475  North American Savings Bank  \n",
       "476  North American Savings Bank  \n",
       "477  North American Savings Bank  \n",
       "478  North American Savings Bank  \n",
       "479  North American Savings Bank  \n",
       "480  North American Savings Bank  \n",
       "481  North American Savings Bank  \n",
       "482  North American Savings Bank  \n",
       "483  North American Savings Bank  \n",
       "484  North American Savings Bank  \n",
       "485  North American Savings Bank  \n",
       "486  North American Savings Bank  \n",
       "487  North American Savings Bank  \n",
       "488  North American Savings Bank  \n",
       "489  North American Savings Bank  \n",
       "490  North American Savings Bank  \n",
       "491  North American Savings Bank  \n",
       "492  North American Savings Bank  \n",
       "493  North American Savings Bank  \n",
       "494  North American Savings Bank  \n",
       "495  North American Savings Bank  \n",
       "496  North American Savings Bank  \n",
       "497  North American Savings Bank  \n",
       "498  North American Savings Bank  \n",
       "499  North American Savings Bank  \n",
       "500  North American Savings Bank  \n",
       "501  North American Savings Bank  \n",
       "502  North American Savings Bank  \n",
       "503  North American Savings Bank  \n",
       "504  North American Savings Bank  \n",
       "\n",
       "[505 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['Stars']\n",
    "x=data['Reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70-30 data split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353,)\n",
      "(152,)\n",
      "(353,)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data preparation :\n",
    "    -> Tokenization = uni-grams\n",
    "    -> Removing English stopwords,digits and special characters.\n",
    "    -> Density=95% and Sparsity=1% (1%<Word frequency<95%)\n",
    "    -> Lower-case\n",
    "    -> Used lemmatization (done separately below)\n",
    "'''\n",
    "\n",
    "vect = CountVectorizer(max_df=.95,min_df=0.01,stop_words='english',token_pattern='(?u)\\\\b[a-zA-Z]{2,}\\\\w\\\\w+\\\\b')\n",
    "#vect = CountVectorizer(tokenizer=split_into_lemmas(), max_df=.95,min_df=0.01,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<152x680 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3394 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''      <chars meaning><Identifiers>\n",
    "#df['TEXT'] = df['TEXT'].str.replace('\\d+', '') # for digits\n",
    "#df['TEXT'] = df['TEXT'].str.replace(r'(\\b\\w{1,2}\\b)', '') # for words\n",
    "#df['TEXT'] = df['TEXT'].str.replace('[^\\w\\s]', '') # for punctuation \n",
    "'''\n",
    "\n",
    "'''      <Traing on diff vocab>\n",
    "x_test_dtm = vect.fit_transform(x_test)\n",
    "x_test_dtm\n",
    "\n",
    "o/p:        <152x680 sparse matrix of type '<class 'numpy.int64'>'\n",
    "            with 3394 stored elements in Compressed Sparse Row format>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.95, max_features=None, min_df=0.01,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b[a-zA-Z]{2,}\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn training data vocabulary\n",
    "vect.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then create document-term matrix\n",
    "x_train_dtm = vect.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<353x591 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7228 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 2, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform to an dense matrix\n",
    "x_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making test data dtm\n",
    "x_test_dtm = vect.transform(x_test)\n",
    "x_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mac\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\mac\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaron', 'able', 'absolutely', 'accept', 'accepted', 'account', 'accurate', 'actual', 'adam', 'adan', 'additional', 'address', 'agent', 'alex', 'amazing', 'american', 'annoyed', 'answer', 'answered', 'answering', 'answers', 'antebellum', 'anthony', 'application', 'apply', 'appraisal', 'appraise', 'appraiser', 'appreciate', 'appreciated', 'approval', 'approved', 'arose', 'asked', 'asking', 'asset', 'assurance', 'attention', 'attentive', 'attitude', 'available', 'aware', 'away', 'awesome', 'bank', 'banker', 'banks', 'barrett', 'based', 'basis']\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "# eg\n",
    "lemmatizer.lemmatize(\"played\",'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying lemmatization\n",
    "x_train_tokens_root=[]\n",
    "for w in x_train_tokens:\n",
    "    x_train_tokens_root.append(lemmatizer.lemmatize(w,'v'))\n",
    "    #print(rootWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaron',\n",
       " 'able',\n",
       " 'absolutely',\n",
       " 'accept',\n",
       " 'accept',\n",
       " 'account',\n",
       " 'accurate',\n",
       " 'actual',\n",
       " 'adam',\n",
       " 'adan',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'agent',\n",
       " 'alex',\n",
       " 'amaze',\n",
       " 'american',\n",
       " 'annoy',\n",
       " 'answer',\n",
       " 'answer',\n",
       " 'answer',\n",
       " 'answer',\n",
       " 'antebellum',\n",
       " 'anthony',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appraisal',\n",
       " 'appraise',\n",
       " 'appraiser',\n",
       " 'appreciate',\n",
       " 'appreciate',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'arise',\n",
       " 'ask',\n",
       " 'ask',\n",
       " 'asset',\n",
       " 'assurance',\n",
       " 'attention',\n",
       " 'attentive',\n",
       " 'attitude',\n",
       " 'available',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'bank',\n",
       " 'barrett',\n",
       " 'base',\n",
       " 'basis',\n",
       " 'beat',\n",
       " 'begin',\n",
       " 'begin',\n",
       " 'begin',\n",
       " 'believe',\n",
       " 'beneficial',\n",
       " 'best',\n",
       " 'better',\n",
       " 'brent',\n",
       " 'broker',\n",
       " 'business',\n",
       " 'buyer',\n",
       " 'buyers',\n",
       " 'buy',\n",
       " 'call',\n",
       " 'call',\n",
       " 'call',\n",
       " 'calm',\n",
       " 'come',\n",
       " 'capital',\n",
       " 'care',\n",
       " 'care',\n",
       " 'case',\n",
       " 'cause',\n",
       " 'certainly',\n",
       " 'challenge',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'check',\n",
       " 'choose',\n",
       " 'chris',\n",
       " 'circumstances',\n",
       " 'clarification',\n",
       " 'class',\n",
       " 'clear',\n",
       " 'client',\n",
       " 'clients',\n",
       " 'close',\n",
       " 'close',\n",
       " 'close',\n",
       " 'come',\n",
       " 'comfortable',\n",
       " 'commitment',\n",
       " 'commit',\n",
       " 'communicate',\n",
       " 'communicate',\n",
       " 'communication',\n",
       " 'company',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'competent',\n",
       " 'competitive',\n",
       " 'complain',\n",
       " 'complete',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complicate',\n",
       " 'comps',\n",
       " 'concern',\n",
       " 'confident',\n",
       " 'con',\n",
       " 'consider',\n",
       " 'constant',\n",
       " 'consultant',\n",
       " 'contact',\n",
       " 'contact',\n",
       " 'continue',\n",
       " 'contract',\n",
       " 'conventional',\n",
       " 'conversation',\n",
       " 'conversations',\n",
       " 'cost',\n",
       " 'cost',\n",
       " 'couldn',\n",
       " 'course',\n",
       " 'credit',\n",
       " 'current',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'daily',\n",
       " 'dallas',\n",
       " 'date',\n",
       " 'days',\n",
       " 'deal',\n",
       " 'deal',\n",
       " 'dean',\n",
       " 'decide',\n",
       " 'decide',\n",
       " 'decision',\n",
       " 'definitely',\n",
       " 'demeanor',\n",
       " 'despite',\n",
       " 'detail',\n",
       " 'detail',\n",
       " 'didn',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'disappoint',\n",
       " 'disorganize',\n",
       " 'documentation',\n",
       " 'document',\n",
       " 'do',\n",
       " 'do',\n",
       " 'dream',\n",
       " 'earlier',\n",
       " 'easier',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'educate',\n",
       " 'efficient',\n",
       " 'email',\n",
       " 'email',\n",
       " 'email',\n",
       " 'encounter',\n",
       " 'end',\n",
       " 'ensure',\n",
       " 'entire',\n",
       " 'error',\n",
       " 'errors',\n",
       " 'escrow',\n",
       " 'especially',\n",
       " 'estimate',\n",
       " 'exceed',\n",
       " 'excellent',\n",
       " 'expect',\n",
       " 'expectations',\n",
       " 'expect',\n",
       " 'experience',\n",
       " 'experience',\n",
       " 'experience',\n",
       " 'expertise',\n",
       " 'expire',\n",
       " 'explain',\n",
       " 'explain',\n",
       " 'explain',\n",
       " 'explanation',\n",
       " 'express',\n",
       " 'extra',\n",
       " 'extremely',\n",
       " 'fact',\n",
       " 'fail',\n",
       " 'family',\n",
       " 'fantastic',\n",
       " 'fast',\n",
       " 'feel',\n",
       " 'fee',\n",
       " 'felt',\n",
       " 'finally',\n",
       " 'financial',\n",
       " 'finance',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'fix',\n",
       " 'follow',\n",
       " 'forget',\n",
       " 'forward',\n",
       " 'fred',\n",
       " 'free',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'frustrate',\n",
       " 'fully',\n",
       " 'fund',\n",
       " 'future',\n",
       " 'give',\n",
       " 'get',\n",
       " 'goals',\n",
       " 'go',\n",
       " 'good',\n",
       " 'goodlet',\n",
       " 'goodness',\n",
       " 'great',\n",
       " 'guarantee',\n",
       " 'guide',\n",
       " 'guy',\n",
       " 'handle',\n",
       " 'hand',\n",
       " 'happen',\n",
       " 'happen',\n",
       " 'happen',\n",
       " 'happier',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'have',\n",
       " 'hear',\n",
       " 'help',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'help',\n",
       " 'hesitate',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highly',\n",
       " 'hold',\n",
       " 'home',\n",
       " 'homebuyer',\n",
       " 'home',\n",
       " 'honest',\n",
       " 'honestly',\n",
       " 'hope',\n",
       " 'horrible',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'house',\n",
       " 'huge',\n",
       " 'hang',\n",
       " 'husband',\n",
       " 'idea',\n",
       " 'immediately',\n",
       " 'impress',\n",
       " 'include',\n",
       " 'income',\n",
       " 'incredibly',\n",
       " 'industry',\n",
       " 'information',\n",
       " 'informative',\n",
       " 'inform',\n",
       " 'initial',\n",
       " 'initially',\n",
       " 'institution',\n",
       " 'interest',\n",
       " 'involve',\n",
       " 'issue',\n",
       " 'items',\n",
       " 'jason',\n",
       " 'jocovic',\n",
       " 'joey',\n",
       " 'john',\n",
       " 'june',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'kind',\n",
       " 'know',\n",
       " 'know',\n",
       " 'know',\n",
       " 'knowledgable',\n",
       " 'knowledge',\n",
       " 'knowledgeable',\n",
       " 'know',\n",
       " 'kory',\n",
       " 'late',\n",
       " 'later',\n",
       " 'leave',\n",
       " 'lender',\n",
       " 'lenders',\n",
       " 'lend',\n",
       " 'letter',\n",
       " 'level',\n",
       " 'life',\n",
       " 'like',\n",
       " 'line',\n",
       " 'list',\n",
       " 'little',\n",
       " 'loan',\n",
       " 'loan',\n",
       " 'local',\n",
       " 'lock',\n",
       " 'lock',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'look',\n",
       " 'lower',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'manner',\n",
       " 'market',\n",
       " 'matter',\n",
       " 'meet',\n",
       " 'mention',\n",
       " 'message',\n",
       " 'mile',\n",
       " 'military',\n",
       " 'minutes',\n",
       " 'miss',\n",
       " 'mistake',\n",
       " 'money',\n",
       " 'month',\n",
       " 'monthly',\n",
       " 'months',\n",
       " 'mortgage',\n",
       " 'mortgage',\n",
       " 'multiple',\n",
       " 'nasb',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'need',\n",
       " 'need',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'north',\n",
       " 'notary',\n",
       " 'note',\n",
       " 'notifications',\n",
       " 'obtain',\n",
       " 'offer',\n",
       " 'offer',\n",
       " 'offer',\n",
       " 'officer',\n",
       " 'online',\n",
       " 'options',\n",
       " 'orient',\n",
       " 'original',\n",
       " 'originally',\n",
       " 'origination',\n",
       " 'overall',\n",
       " 'pacific',\n",
       " 'pay',\n",
       " 'painless',\n",
       " 'paperwork',\n",
       " 'passionate',\n",
       " 'past',\n",
       " 'patient',\n",
       " 'patiently',\n",
       " 'patrick',\n",
       " 'payments',\n",
       " 'people',\n",
       " 'person',\n",
       " 'personable',\n",
       " 'personal',\n",
       " 'personally',\n",
       " 'peter',\n",
       " 'phone',\n",
       " 'picture',\n",
       " 'plan',\n",
       " 'pleasant',\n",
       " 'please',\n",
       " 'pleasure',\n",
       " 'plenty',\n",
       " 'point',\n",
       " 'polite',\n",
       " 'poor',\n",
       " 'positive',\n",
       " 'possible',\n",
       " 'potential',\n",
       " 'pretty',\n",
       " 'previous',\n",
       " 'prior',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'process',\n",
       " 'product',\n",
       " 'products',\n",
       " 'professional',\n",
       " 'professionalism',\n",
       " 'professionally',\n",
       " 'promise',\n",
       " 'promise',\n",
       " 'prompt',\n",
       " 'promptly',\n",
       " 'properties',\n",
       " 'property',\n",
       " 'pros',\n",
       " 'provide',\n",
       " 'provide',\n",
       " 'purchase',\n",
       " 'purchase',\n",
       " 'purchase',\n",
       " 'question',\n",
       " 'question',\n",
       " 'question',\n",
       " 'quick',\n",
       " 'quickly',\n",
       " 'quite',\n",
       " 'rate',\n",
       " 'rat',\n",
       " 'reach',\n",
       " 'reach',\n",
       " 'read',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'really',\n",
       " 'realtor',\n",
       " 'reason',\n",
       " 'receive',\n",
       " 'receive',\n",
       " 'recommend',\n",
       " 'recommendation',\n",
       " 'recommend',\n",
       " 'record',\n",
       " 'refi',\n",
       " 'refinance',\n",
       " 'refinance',\n",
       " 'refinance',\n",
       " 'regulations',\n",
       " 'reliance',\n",
       " 'request',\n",
       " 'request',\n",
       " 'request',\n",
       " 'require',\n",
       " 'respectful',\n",
       " 'respond',\n",
       " 'respond',\n",
       " 'response',\n",
       " 'responses',\n",
       " 'responsive',\n",
       " 'responsiveness',\n",
       " 'result',\n",
       " 'retirement',\n",
       " 'return',\n",
       " 'review',\n",
       " 'review',\n",
       " 'richter',\n",
       " 'rick',\n",
       " 'right',\n",
       " 'rowel',\n",
       " 'say',\n",
       " 'sale',\n",
       " 'sales',\n",
       " 'satisfy',\n",
       " 'save',\n",
       " 'save',\n",
       " 'save',\n",
       " 'say',\n",
       " 'schedule',\n",
       " 'seamless',\n",
       " 'second',\n",
       " 'sell',\n",
       " 'sell',\n",
       " 'send',\n",
       " 'send',\n",
       " 'service',\n",
       " 'service',\n",
       " 'settlement',\n",
       " 'settle',\n",
       " 'show',\n",
       " 'sign',\n",
       " 'simple',\n",
       " 'situation',\n",
       " 'small',\n",
       " 'smooth',\n",
       " 'smoothly',\n",
       " 'special',\n",
       " 'specifically',\n",
       " 'spend',\n",
       " 'speak',\n",
       " 'staff',\n",
       " 'star',\n",
       " 'star',\n",
       " 'start',\n",
       " 'start',\n",
       " 'state',\n",
       " 'status',\n",
       " 'stay',\n",
       " 'steer',\n",
       " 'stellar',\n",
       " 'step',\n",
       " 'stephanie',\n",
       " 'steve',\n",
       " 'steven',\n",
       " 'stressful',\n",
       " 'successful',\n",
       " 'suggest',\n",
       " 'super',\n",
       " 'support',\n",
       " 'sure',\n",
       " 'sweet',\n",
       " 'take',\n",
       " 'talk',\n",
       " 'talk',\n",
       " 'talk',\n",
       " 'tax',\n",
       " 'team',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'term',\n",
       " 'text',\n",
       " 'thank',\n",
       " 'thank',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'think',\n",
       " 'thousands',\n",
       " 'time',\n",
       " 'timely',\n",
       " 'time',\n",
       " 'tell',\n",
       " 'tons',\n",
       " 'take',\n",
       " 'total',\n",
       " 'tough',\n",
       " 'transaction',\n",
       " 'treat',\n",
       " 'tree',\n",
       " 'tremendous',\n",
       " 'try',\n",
       " 'triumph',\n",
       " 'true',\n",
       " 'truly',\n",
       " 'trust',\n",
       " 'trust',\n",
       " 'try',\n",
       " 'twice',\n",
       " 'type',\n",
       " 'understand',\n",
       " 'understand',\n",
       " 'unique',\n",
       " 'unless',\n",
       " 'unlike',\n",
       " 'unpleasant',\n",
       " 'unprofessional',\n",
       " 'use',\n",
       " 'use',\n",
       " 'usually',\n",
       " 'various',\n",
       " 'versus',\n",
       " 'veteran',\n",
       " 'waive',\n",
       " 'walk',\n",
       " 'walk',\n",
       " 'want',\n",
       " 'want',\n",
       " 'wasn',\n",
       " 'waste',\n",
       " 'website',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'weeks',\n",
       " 'go',\n",
       " 'weren',\n",
       " 'wife',\n",
       " 'will',\n",
       " 'wonderful',\n",
       " 'work',\n",
       " 'work',\n",
       " 'work',\n",
       " 'work',\n",
       " 'wouldn',\n",
       " 'wrong',\n",
       " 'wyndham',\n",
       " 'year',\n",
       " 'years']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tokens_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(words):\n",
    "    counts = dict()\n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Key positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=.95,min_df=0.01,stop_words='english',token_pattern='(?u)\\\\b[a-zA-Z]{2,}\\\\w\\\\w+\\\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_dtm = vect.fit_transform(data['Reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<505x543 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10011 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_tokens = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first presence of the word and where\n",
    "#vocab_data = vect.vocabulary_\n",
    "#type(vocab_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_word_list=[]\n",
    "neu_word_list=[]\n",
    "neg_word_list=[]\n",
    "\n",
    "for word in x_data_tokens:\n",
    "    if (sid.polarity_scores(word)['compound']) >= 0.1:\n",
    "        pos_word_list.append(word)\n",
    "    elif (sid.polarity_scores(word)['compound']) <= -0.1:\n",
    "        neg_word_list.append(word)\n",
    "    else:\n",
    "        neu_word_list.append(word)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count = []\n",
    "for word in pos_word_list:\n",
    "    count=0\n",
    "    for text in data['Reviews']:\n",
    "        if word in text:\n",
    "            count=count+1\n",
    "    pos_count.append(count)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_count))\n",
    "print(len(pos_word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.Series(pos_count,name='count')\n",
    "b=pd.Series(pos_word_list,name='Positive Words')\n",
    "c = pd.concat([b,a],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive Words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>recommend</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>help</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>sure</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>great</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>best</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>easy</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>friend</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>responsive</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>helpful</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>like</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Positive Words  count\n",
       "64      recommend    168\n",
       "42           help    120\n",
       "73           sure    111\n",
       "39          great     92\n",
       "11           best     75\n",
       "26           easy     59\n",
       "35         friend     58\n",
       "66     responsive     56\n",
       "43        helpful     54\n",
       "51           like     47"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive words\n",
    "c.sort_values(by='count',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_count = []\n",
    "for word in neg_word_list:\n",
    "    count=0\n",
    "    for text in data['Reviews']:\n",
    "        if word in text:\n",
    "            count=count+1\n",
    "    neg_count.append(count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(neg_count))\n",
    "print(len(neg_word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.Series(neg_count,name='count')\n",
    "e=pd.Series(neg_word_list,name='Negative Word')\n",
    "f = pd.concat([e,d],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative Word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hard</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>problem</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stressful</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lower</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>problems</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mistake</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>failed</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>difficult</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>poor</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>unprofessional</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Negative Word  count\n",
       "6             hard     42\n",
       "12         problem     31\n",
       "14       stressful     24\n",
       "8            lower     23\n",
       "13        problems     16\n",
       "10         mistake     16\n",
       "5           failed     10\n",
       "2        difficult      9\n",
       "11            poor      8\n",
       "16  unprofessional      7"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative words\n",
    "f.sort_values(by='count',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_count = np.sum(x_data_dtm.toarray(),axis=0)\n",
    "len(x_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaron</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>able</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accept</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>account</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>accurate</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>actual</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adam</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adan</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>additional</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>advice</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>agent</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>agreed</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>alex</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>amazing</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>american</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>annoyed</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>answer</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>answered</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>answering</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>answers</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>antebellum</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>anthony</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>application</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>apply</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>appraisal</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>appraiser</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>appreciate</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>appreciated</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>approval</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>used</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>using</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>usually</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>various</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>versus</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>veteran</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>walk</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>walked</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>want</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>wanted</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>wasn</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>website</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>week</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>weekends</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>weeks</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>went</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>weren</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>wife</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>willing</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>word</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>work</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>worked</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>working</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>works</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>wouldn</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>wrong</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>wyndham</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>year</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>years</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           token  count\n",
       "0          aaron     23\n",
       "1           able     47\n",
       "2     absolutely     13\n",
       "3         accept      6\n",
       "4        account     15\n",
       "5       accurate     10\n",
       "6         actual      8\n",
       "7           adam     39\n",
       "8           adan     14\n",
       "9     additional     16\n",
       "10        advice      7\n",
       "11         agent     13\n",
       "12        agreed      7\n",
       "13          alex     57\n",
       "14       amazing     31\n",
       "15      american      9\n",
       "16       annoyed      6\n",
       "17        answer     26\n",
       "18      answered     27\n",
       "19     answering     11\n",
       "20       answers     13\n",
       "21    antebellum      6\n",
       "22       anthony     28\n",
       "23   application     19\n",
       "24         apply      6\n",
       "25     appraisal     33\n",
       "26     appraiser     10\n",
       "27    appreciate      6\n",
       "28   appreciated     12\n",
       "29      approval     12\n",
       "..           ...    ...\n",
       "513         used     21\n",
       "514        using     20\n",
       "515      usually      7\n",
       "516      various      7\n",
       "517       versus      6\n",
       "518      veteran      9\n",
       "519         walk      6\n",
       "520       walked      6\n",
       "521         want     29\n",
       "522       wanted     23\n",
       "523         wasn     15\n",
       "524      website     10\n",
       "525         week     28\n",
       "526     weekends      8\n",
       "527        weeks     62\n",
       "528         went     70\n",
       "529        weren     14\n",
       "530         wife     25\n",
       "531      willing      7\n",
       "532    wonderful     14\n",
       "533         word      8\n",
       "534         work    128\n",
       "535       worked     83\n",
       "536      working     76\n",
       "537        works     11\n",
       "538       wouldn     13\n",
       "539        wrong      7\n",
       "540      wyndham     16\n",
       "541         year     13\n",
       "542        years     46\n",
       "\n",
       "[543 rows x 2 columns]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_count_df = pd.DataFrame({'token':x_data_tokens, 'count':x_data_count})\n",
    "x_data_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading https://files.pythonhosted.org/packages/60/f0/1d9bfcc8ee6b83472ec571406bd0dd51c0e6330ff1a51b2d29861d389e85/textblob-0.15.3-py2.py3-none-any.whl (636kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\mac\\anaconda3\\lib\\site-packages (from textblob) (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\mac\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\mac\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (3.4.0.3)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text): \n",
    "    analysis = TextBlob(text) \n",
    "    if analysis.sentiment.polarity > 0: \n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0: \n",
    "        return 'neutral'\n",
    "    else: \n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_sentiment = []\n",
    "for reviews in data['Reviews']:\n",
    "    reviews_sentiment.append(get_sentiment(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reviews_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = pd.Series(data['Reviews'],name=\"Review\")\n",
    "review_sentiment = pd.Series(reviews_sentiment,name=\"Sentiment\")\n",
    "Table = pd.concat([review_text,review_sentiment],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I had the pleasure of working with Wyndham Cap...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>My experience with Mattison was beyond greatly...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Patrick answered all my questions by email imm...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I loved working with this group of people! The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Great web interface for both the loan applicat...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Working with Michelle and Wyndham went really ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>usten Butler brought the humanity and connecti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jay was easy to get a hold of if I had any que...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>If I had a million Friends I would recommend a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chaz was fantastic throughout the entire lendi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Austen has been awsome in every step of the wa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The salesperson kept pushing a cash out refi o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>This was the worst experience ever. It was lik...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A good rate but a very frustrating process, co...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>They were not upfront. Learn from my mistake.....</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Initially, the Mortgage Broker was very friend...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Initially, the Mortgage Broker was very friend...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I worked with Kory and Carla at NASB. They wer...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Kory was by far the best loan officer I have e...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Expert loan officer, well versed in VA and the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The NASB team went above and beyond for me and...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dallas Goodlet and his entire team are deservi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Comments: To begin my wife and I were at the p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Working with Jon was such an amazing experienc...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NASB was amazing to work with! The pre-approva...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>\\r\\nJoey was knowledgeable, very accessible an...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>\\r\\nI was hesitant to use a non-local mortgage...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>\\r\\nI was hesitant to use a non-local mortgage...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>\\r\\nSteve got it done when others couldn't. 30...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>\\r\\nVery professional and customer oriented.\\r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>\\r\\nSteve was very responsive and patient with...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>\\r\\nGreat bank with great products.  Easily th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>\\r\\nDallas is very experienced and knowledgeab...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>\\r\\nI was extremely impressed with the proffes...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>\\r\\nI was extremely impressed with the proffes...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>\\r\\nRC Malcolm was excellent, he stayed on top...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>\\r\\nExcellent service . RC stayed on top of ev...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>\\r\\nThey completed everything on time to get u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>\\r\\nBrad was helpful through the entire proces...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>\\r\\nI will recommend everyone I know to NASB a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>\\r\\nOur refinance process was a dream once we ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>\\r\\nThe closing process for a VA loan went smo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>\\r\\nMiserable experience. They screwed up ever...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>\\r\\nOur loan officer was happy to communicate ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>\\r\\nOur loan officer was happy to communicate ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>\\r\\nStarted refinance with Nick things were go...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>\\r\\ncan someone explain why the APR is more th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>\\r\\nThis loan started off quite well. Our rep,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>\\r\\nBuilt new home and wanted to get a small m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>\\r\\nThis Lender contacted my previous phone nu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>\\r\\nI never write reviews but had to this time...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>\\r\\nIt all started when Bob G ran a credit che...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>\\r\\nWhat a horrible experience. We have excell...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>\\r\\nRep was extremely professional, friendly, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>\\r\\nI was working with a loan consultant from ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review Sentiment\n",
       "0    Great job, Wyndham Capital! Each person was pr...  positive\n",
       "1    Matthew Richardson is professional and helpful...  positive\n",
       "2    We had a past experience with Wyndham Mortgage...  negative\n",
       "3    We have been dealing with Brad Thomka from the...  positive\n",
       "4    I can't express how grateful I am for the supp...  positive\n",
       "5    I had the pleasure of working with Wyndham Cap...  positive\n",
       "6    My experience with Mattison was beyond greatly...  positive\n",
       "7    Patrick answered all my questions by email imm...  positive\n",
       "8    I loved working with this group of people! The...  positive\n",
       "9    Great web interface for both the loan applicat...  positive\n",
       "10   Working with Michelle and Wyndham went really ...  positive\n",
       "11   usten Butler brought the humanity and connecti...  positive\n",
       "12   Jay was easy to get a hold of if I had any que...  positive\n",
       "13   If I had a million Friends I would recommend a...  positive\n",
       "14   Chaz was fantastic throughout the entire lendi...  positive\n",
       "15   Austen has been awsome in every step of the wa...  positive\n",
       "16   The salesperson kept pushing a cash out refi o...  positive\n",
       "17   This was the worst experience ever. It was lik...  negative\n",
       "18   A good rate but a very frustrating process, co...  positive\n",
       "19   They were not upfront. Learn from my mistake.....  positive\n",
       "20   Initially, the Mortgage Broker was very friend...  positive\n",
       "21   Initially, the Mortgage Broker was very friend...  positive\n",
       "22   I worked with Kory and Carla at NASB. They wer...  positive\n",
       "23   Kory was by far the best loan officer I have e...  positive\n",
       "24   Expert loan officer, well versed in VA and the...  positive\n",
       "25   The NASB team went above and beyond for me and...  positive\n",
       "26   Dallas Goodlet and his entire team are deservi...  positive\n",
       "27   Comments: To begin my wife and I were at the p...  positive\n",
       "28   Working with Jon was such an amazing experienc...  positive\n",
       "29   NASB was amazing to work with! The pre-approva...  positive\n",
       "..                                                 ...       ...\n",
       "475  \\r\\nJoey was knowledgeable, very accessible an...  positive\n",
       "476  \\r\\nI was hesitant to use a non-local mortgage...  positive\n",
       "477  \\r\\nI was hesitant to use a non-local mortgage...  positive\n",
       "478  \\r\\nSteve got it done when others couldn't. 30...  positive\n",
       "479  \\r\\nVery professional and customer oriented.\\r...  positive\n",
       "480  \\r\\nSteve was very responsive and patient with...  positive\n",
       "481  \\r\\nGreat bank with great products.  Easily th...  positive\n",
       "482  \\r\\nDallas is very experienced and knowledgeab...  positive\n",
       "483  \\r\\nI was extremely impressed with the proffes...  positive\n",
       "484  \\r\\nI was extremely impressed with the proffes...  positive\n",
       "485  \\r\\nRC Malcolm was excellent, he stayed on top...  positive\n",
       "486  \\r\\nExcellent service . RC stayed on top of ev...  positive\n",
       "487  \\r\\nThey completed everything on time to get u...  positive\n",
       "488  \\r\\nBrad was helpful through the entire proces...  positive\n",
       "489  \\r\\nI will recommend everyone I know to NASB a...  positive\n",
       "490  \\r\\nOur refinance process was a dream once we ...  positive\n",
       "491  \\r\\nThe closing process for a VA loan went smo...  positive\n",
       "492  \\r\\nMiserable experience. They screwed up ever...  negative\n",
       "493  \\r\\nOur loan officer was happy to communicate ...  positive\n",
       "494  \\r\\nOur loan officer was happy to communicate ...  positive\n",
       "495  \\r\\nStarted refinance with Nick things were go...  positive\n",
       "496  \\r\\ncan someone explain why the APR is more th...  positive\n",
       "497  \\r\\nThis loan started off quite well. Our rep,...  positive\n",
       "498  \\r\\nBuilt new home and wanted to get a small m...  positive\n",
       "499  \\r\\nThis Lender contacted my previous phone nu...  negative\n",
       "500  \\r\\nI never write reviews but had to this time...  positive\n",
       "501  \\r\\nIt all started when Bob G ran a credit che...  positive\n",
       "502  \\r\\nWhat a horrible experience. We have excell...  positive\n",
       "503  \\r\\nRep was extremely professional, friendly, ...  positive\n",
       "504  \\r\\nI was working with a loan consultant from ...  positive\n",
       "\n",
       "[505 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    466\n",
       "negative     35\n",
       "neutral       4\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identify keys themes of issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.39978659 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.6888569  0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.1158803  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Creating Tf-idf matix\n",
    "vect_tfidf = TfidfVectorizer(max_df=.95,min_df=0.01,stop_words='english',token_pattern='(?u)\\\\b[a-zA-Z]\\\\w\\\\w+\\\\b')\n",
    "data_tfidf = vect_tfidf.fit_transform(data['Reviews'])\n",
    "data_tfidf\n",
    "print(data_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=10,learning_method='online',max_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_topics = lda_model.fit_transform(data_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words = lda_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vect_tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 8\n",
    "topic_summaries = []\n",
    "for i,topic_dist in enumerate(topic_words):\n",
    "    topic_word=np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['response bank called credit just nasb letter real',\n",
       " 'kory completed check closing little decision took bob',\n",
       " 'process great loan home recommend work time team',\n",
       " 'unprofessional previous various number list contacted encountered responses',\n",
       " 'kory complicated tough properties calm responsiveness dealing wouldn',\n",
       " 'jon barrett beginning timely knowledgeable oriented able professional',\n",
       " 'best awesome homes nasb purchased got far experience',\n",
       " 'responsive poor informative lock good expired surprises attentive',\n",
       " 'bad product don tree companies offer lending months',\n",
       " 'surprises jeremy joey mortgage local trusted nasb process']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics(important):\n",
    "    -> Great process,great online facilites,timely response\n",
    "    -> Unprofessional behaviour of employees\n",
    "    -> Good loan services and closing rate\n",
    "    -> Super fast process\n",
    "    -> Higher rates or bank payments\n",
    "    -> About Kory Anthony\n",
    "    -> Good professionalism\n",
    "    -> Trusted bank and positive attitude of workers\n",
    "    -> Timely services\n",
    "    -> Hard and patient employes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Predict ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    410\n",
       "1     95\n",
       "Name: Stars, dtype: int64"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Stars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(text): \n",
    "    analysis = TextBlob(text) \n",
    "    sent=analysis.sentiment.polarity\n",
    "    if sent > 0: \n",
    "        if sent > 0.2:\n",
    "            return 5\n",
    "        else:        \n",
    "            return 4\n",
    "    elif sent < 0: \n",
    "        if sent < -0.2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    else: \n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rating = []\n",
    "for rate in x_train:\n",
    "    pred_rating.append(get_rating(rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rating_test = []\n",
    "for rate in x_test:\n",
    "    pred_rating_test.append(get_rating(rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5855263157894737\n"
     ]
    }
   ],
   "source": [
    "# test sample\n",
    "print(metrics.accuracy_score(y_test, pred_rating_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6288951841359773\n"
     ]
    }
   ],
   "source": [
    "# train sample\n",
    "print(metrics.accuracy_score(y_train, pred_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(x_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = nb.predict(x_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 1, 5, 5, 5, 5, 1, 5, 5, 1, 5, 5,\n",
       "       5, 1, 1, 5, 5, 5, 5, 1, 5, 5, 5, 1, 1, 1, 5, 5, 5, 5, 1, 5, 5, 5,\n",
       "       1, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 5,\n",
       "       5, 5, 1, 5, 1, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 1, 5, 5, 5, 1, 5, 5,\n",
       "       1, 5, 5, 5, 5, 1, 5, 5, 5, 1, 1, 5, 5, 5, 5, 5, 5, 1, 1, 5, 5, 5,\n",
       "       5, 5, 5, 5, 1, 5, 5, 5, 5, 1, 5, 5, 1, 5, 1, 5, 5, 5, 1, 5, 5, 5,\n",
       "       5, 5, 1, 5, 1, 5, 5, 5, 1, 5, 5, 5, 5, 5, 1, 5, 5, 1, 5, 5],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30   4]\n",
      " [  7 111]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = nb.predict_proba(x_test_dtm)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9276315789473685\n",
      "0.969840478564307\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "# calculate AUC\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mac\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(x_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = logreg.predict(x_test_dtm)\n",
    "y_pred_prob = logreg.predict_proba(x_test_dtm)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8947368421052632\n",
      "0.8925722831505485\n"
     ]
    }
   ],
   "source": [
    "# calculating accuracy and AUC\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
